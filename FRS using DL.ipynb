{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17b6fb29",
   "metadata": {},
   "source": [
    "## `Part 1: Generate dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20784e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def generate_dataset():\n",
    "    # Ensure the cascade file exists\n",
    "    cascade_path = \"haarcascade_frontalface_default.xml\"\n",
    "    if not os.path.exists(cascade_path):\n",
    "        print(f\"Error: Cascade file '{cascade_path}' not found.\")\n",
    "        return\n",
    "    \n",
    "    face_classifier = cv2.CascadeClassifier(cascade_path)\n",
    "    \n",
    "    # Ensure data directory exists\n",
    "    if not os.path.exists(\"data\"):\n",
    "        os.makedirs(\"data\")\n",
    "    \n",
    "    def face_cropped(img):\n",
    "        if img is None:\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "            \n",
    "            if len(faces) == 0:  # Fixed: use len() instead of comparing with ()\n",
    "                return None\n",
    "                \n",
    "            for (x, y, w, h) in faces:\n",
    "                cropped_face = img[y:y+h, x:x+w]\n",
    "                return cropped_face\n",
    "                \n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error in face_cropped: {e}\")\n",
    "            return None\n",
    "    \n",
    "    # Try different camera indices\n",
    "    camera_index = 0\n",
    "    max_attempts = 3\n",
    "    \n",
    "    for i in range(max_attempts):\n",
    "        print(f\"Trying camera index {camera_index}\")\n",
    "        cap = cv2.VideoCapture(camera_index, cv2.CAP_DSHOW)  # Use DirectShow on Windows\n",
    "        \n",
    "        if cap.isOpened():\n",
    "            print(f\"Successfully opened camera with index {camera_index}\")\n",
    "            # Wait for camera to initialize\n",
    "            import time\n",
    "            time.sleep(2)\n",
    "            ret, test_frame = cap.read()\n",
    "            if ret and test_frame is not None:\n",
    "                print(\"Camera providing valid frames\")\n",
    "                break\n",
    "        \n",
    "        print(f\"Failed with camera index {camera_index}\")\n",
    "        cap.release()\n",
    "        camera_index += 1\n",
    "        \n",
    "        if i == max_attempts - 1:\n",
    "            print(\"Could not initialize any camera\")\n",
    "            return\n",
    "    \n",
    "    id = 1\n",
    "    img_id = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret or frame is None:\n",
    "            print(\"Failed to capture frame\")\n",
    "            break\n",
    "            \n",
    "        face = face_cropped(frame)\n",
    "        \n",
    "        if face is not None:\n",
    "            img_id += 1\n",
    "            face = cv2.resize(face, (200, 200))\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "            file_name_path = f\"data/user.{id}.{img_id}.jpg\"\n",
    "            cv2.imwrite(file_name_path, face)\n",
    "            cv2.putText(face, str(img_id), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)\n",
    "            \n",
    "            cv2.imshow(\"Cropped face\", face)\n",
    "            \n",
    "            # Show the original frame with rectangle\n",
    "            cv2.rectangle(frame, (frame.shape[1]//2-100, frame.shape[0]//2-100), \n",
    "                         (frame.shape[1]//2+100, frame.shape[0]//2+100), (0, 255, 0), 2)\n",
    "            cv2.imshow(\"Video Frame\", frame)\n",
    "        \n",
    "        if cv2.waitKey(1) == 13 or img_id >= 200:  # 13 is the ASCII character of Enter\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"Collecting samples completed. Collected {img_id} samples.\")\n",
    "\n",
    "generate_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9459b06",
   "metadata": {},
   "source": [
    "## `Part 2: Train the classifier and save it`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e9c968",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "def train_classifier(data_dir):\n",
    "    # Check if data directory exists\n",
    "    if not os.path.exists(data_dir):\n",
    "        print(f\"Error: Data directory '{data_dir}' not found.\")\n",
    "        return\n",
    "    \n",
    "    # Get list of image files\n",
    "    path = [os.path.join(data_dir, f) for f in os.listdir(data_dir)]\n",
    "    if not path:\n",
    "        print(f\"Error: No files found in '{data_dir}'.\")\n",
    "        return\n",
    "    \n",
    "    faces = []\n",
    "    ids = []\n",
    "    \n",
    "    for image in path:\n",
    "        try:\n",
    "            img = Image.open(image).convert('L')\n",
    "            imageNp = np.array(img, 'uint8')\n",
    "            id = int(os.path.split(image)[1].split(\".\")[1])\n",
    "            \n",
    "            faces.append(imageNp)\n",
    "            ids.append(id)\n",
    "            # print(f\"Processing image: {os.path.basename(image)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image}: {e}\")\n",
    "    \n",
    "    if not faces:\n",
    "        print(\"No valid face images found.\")\n",
    "        return\n",
    "        \n",
    "    ids = np.array(ids)\n",
    "    \n",
    "    # Train and save classifier\n",
    "    clf = cv2.face.LBPHFaceRecognizer_create()\n",
    "    print(f\"Training with {len(faces)} images...\")\n",
    "    clf.train(faces, ids)\n",
    "    clf.write(\"classifier.xml\")\n",
    "    print(\"Training completed. Classifier saved as 'classifier.xml'\")\n",
    "\n",
    "train_classifier(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6501d17",
   "metadata": {},
   "source": [
    "## `Part 3: Face detection/recognition`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ac38b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    " \n",
    "def draw_boundary(img, classifier, scaleFactor, minNeighbors, color, text, clf):\n",
    "    if img is None:\n",
    "        return img\n",
    "        \n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    features = classifier.detectMultiScale(gray_img, scaleFactor, minNeighbors)\n",
    "     \n",
    "    for (x,y,w,h) in features:\n",
    "        cv2.rectangle(img, (x,y), (x+w,y+h), color, 2 )\n",
    "         \n",
    "        id, pred = clf.predict(gray_img[y:y+h,x:x+w])\n",
    "        confidence = int(100*(1-pred/300))\n",
    "         \n",
    "        if confidence>85:\n",
    "            if id==1:\n",
    "                cv2.putText(img, \"Sujal\", (x,y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 1, cv2.LINE_AA)\n",
    "            if id==2:\n",
    "                cv2.putText(img, \"Manish\", (x,y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 1, cv2.LINE_AA)\n",
    "        else:\n",
    "            cv2.putText(img, \"UNKNOWN\", (x,y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,0,255), 1, cv2.LINE_AA)\n",
    "     \n",
    "    return img\n",
    " \n",
    "# Check for required files\n",
    "if not os.path.exists(\"haarcascade_frontalface_default.xml\"):\n",
    "    print(\"Error: Missing face cascade file\")\n",
    "    exit()\n",
    "if not os.path.exists(\"classifier.xml\"):\n",
    "    print(\"Error: Missing classifier model file\")\n",
    "    exit()\n",
    "\n",
    "# Loading classifier\n",
    "faceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    " \n",
    "clf = cv2.face.LBPHFaceRecognizer_create()\n",
    "clf.read(\"classifier.xml\")\n",
    " \n",
    "# Try to open camera\n",
    "video_capture = cv2.VideoCapture(0, cv2.CAP_DSHOW)  # Use DirectShow on Windows\n",
    "\n",
    "if not video_capture.isOpened():\n",
    "    print(\"Error: Could not open camera\")\n",
    "    exit()\n",
    "\n",
    "window_name = \"Face Detection\"\n",
    "cv2.namedWindow(window_name)\n",
    " \n",
    "while True:\n",
    "    # Check if window is closed\n",
    "    if cv2.getWindowProperty(window_name, cv2.WND_PROP_VISIBLE) < 1:\n",
    "        print(\"Window closed by user\")\n",
    "        break\n",
    "        \n",
    "    ret, img = video_capture.read()\n",
    "    if not ret or img is None:\n",
    "        print(\"Error reading frame\")\n",
    "        break\n",
    "        \n",
    "    img = draw_boundary(img, faceCascade, 1.3, 6, (255,255,255), \"Face\", clf)\n",
    "    cv2.imshow(window_name, img)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 13 or key == ord('q'):  # 13 is the Enter key\n",
    "        print(\"Exiting...\")\n",
    "        break\n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a691c6dd",
   "metadata": {},
   "source": [
    "## `Part 4 Converting the above project into GUI`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f21d9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, messagebox, scrolledtext\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import threading\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Dark Theme Colors\n",
    "THEME = {\n",
    "    \"bg_dark\": \"#121212\",        # Main background\n",
    "    \"bg_medium\": \"#1E1E1E\",      # Card background\n",
    "    \"bg_light\": \"#2D2D2D\",       # Input fields, headers\n",
    "    \"accent\": \"#BB86FC\",         # Purple accent\n",
    "    \"accent2\": \"#03DAC6\",        # Teal accent \n",
    "    \"error\": \"#CF6679\",          # Error color\n",
    "    \"success\": \"#4CAF50\",        # Success color\n",
    "    \"warning\": \"#FFAB40\",        # Warning color\n",
    "    \"text\": \"#E1E1E1\",           # Primary text\n",
    "    \"text_secondary\": \"#B0B0B0\"  # Secondary text\n",
    "}\n",
    "\n",
    "# Initialize main window with dark theme\n",
    "window = tk.Tk()\n",
    "window.title(\"Face Recognition System\")\n",
    "window.configure(bg=THEME[\"bg_dark\"])\n",
    "window.geometry(\"850x650\")\n",
    "\n",
    "# Configure styles for dark theme\n",
    "style = ttk.Style()\n",
    "style.theme_use(\"clam\")  # Base theme that works well for customization\n",
    "\n",
    "# Configure frame styles\n",
    "style.configure(\"TFrame\", background=THEME[\"bg_dark\"])\n",
    "style.configure(\"Card.TFrame\", background=THEME[\"bg_medium\"], relief=\"flat\")\n",
    "style.configure(\"Header.TFrame\", background=THEME[\"bg_light\"])\n",
    "\n",
    "# Configure label styles\n",
    "style.configure(\"TLabel\", \n",
    "                background=THEME[\"bg_dark\"], \n",
    "                foreground=THEME[\"text\"], \n",
    "                font=(\"Segoe UI\", 11))\n",
    "style.configure(\"Card.TLabel\", background=THEME[\"bg_medium\"], foreground=THEME[\"text\"])\n",
    "style.configure(\"Header.TLabel\", \n",
    "                background=THEME[\"bg_light\"], \n",
    "                foreground=THEME[\"accent\"], \n",
    "                font=(\"Segoe UI\", 14, \"bold\"))\n",
    "style.configure(\"Title.TLabel\", \n",
    "                background=THEME[\"bg_dark\"], \n",
    "                foreground=THEME[\"accent\"], \n",
    "                font=(\"Segoe UI\", 18, \"bold\"))\n",
    "style.configure(\"Status.TLabel\", \n",
    "                background=THEME[\"bg_light\"], \n",
    "                foreground=THEME[\"text\"], \n",
    "                font=(\"Segoe UI\", 10))\n",
    "\n",
    "# Configure button styles\n",
    "style.configure(\"Accent.TButton\", \n",
    "                background=THEME[\"accent\"], \n",
    "                foreground=THEME[\"bg_dark\"], \n",
    "                font=(\"Segoe UI\", 11, \"bold\"),\n",
    "                padding=8)\n",
    "style.map(\"Accent.TButton\",\n",
    "          background=[(\"active\", THEME[\"accent2\"]), (\"disabled\", THEME[\"bg_light\"])])\n",
    "\n",
    "# Configure entry style\n",
    "style.configure(\"TEntry\", \n",
    "                fieldbackground=THEME[\"bg_light\"],\n",
    "                foreground=THEME[\"text\"],\n",
    "                insertcolor=THEME[\"text\"],\n",
    "                font=(\"Segoe UI\", 11))\n",
    "\n",
    "# Configure progress bar\n",
    "style.configure(\"Horizontal.TProgressbar\", \n",
    "                background=THEME[\"accent\"],\n",
    "                troughcolor=THEME[\"bg_light\"],\n",
    "                thickness=15)\n",
    "\n",
    "# Main container\n",
    "main_frame = ttk.Frame(window, style=\"TFrame\")\n",
    "main_frame.pack(fill=tk.BOTH, expand=True, padx=15, pady=15)\n",
    "\n",
    "# App title\n",
    "title_label = ttk.Label(main_frame, text=\"Face Recognition System\", style=\"Title.TLabel\")\n",
    "title_label.pack(fill=tk.X, pady=(0, 15))\n",
    "\n",
    "# User Info Card\n",
    "user_card = ttk.Frame(main_frame, style=\"Card.TFrame\")\n",
    "user_card.pack(fill=tk.X, pady=10, padx=5, ipady=5)\n",
    "\n",
    "user_header = ttk.Frame(user_card, style=\"Header.TFrame\")\n",
    "user_header.pack(fill=tk.X)\n",
    "\n",
    "user_title = ttk.Label(user_header, text=\"User Information\", style=\"Header.TLabel\")\n",
    "user_title.pack(padx=10, pady=5, anchor=tk.W)\n",
    "\n",
    "# User form\n",
    "user_form = ttk.Frame(user_card, style=\"Card.TFrame\")\n",
    "user_form.pack(fill=tk.X, padx=15, pady=10)\n",
    "\n",
    "# Name field with dark theme\n",
    "name_frame = ttk.Frame(user_form, style=\"Card.TFrame\")\n",
    "name_frame.pack(fill=tk.X, pady=5)\n",
    "name_label = ttk.Label(name_frame, text=\"Name:\", width=8, style=\"Card.TLabel\")\n",
    "name_label.pack(side=tk.LEFT, padx=(0, 10))\n",
    "name_entry = ttk.Entry(name_frame)\n",
    "name_entry.pack(side=tk.LEFT, fill=tk.X, expand=True)\n",
    "\n",
    "# Buttons frame\n",
    "buttons_frame = ttk.Frame(main_frame, style=\"Card.TFrame\")\n",
    "buttons_frame.pack(fill=tk.X, pady=10, padx=5, ipady=10)\n",
    "\n",
    "buttons_header = ttk.Frame(buttons_frame, style=\"Header.TFrame\")\n",
    "buttons_header.pack(fill=tk.X)\n",
    "\n",
    "buttons_title = ttk.Label(buttons_header, text=\"Actions\", style=\"Header.TLabel\")\n",
    "buttons_title.pack(padx=10, pady=5, anchor=tk.W)\n",
    "\n",
    "# Button container with even spacing\n",
    "button_container = ttk.Frame(buttons_frame, style=\"Card.TFrame\")\n",
    "button_container.pack(fill=tk.X, padx=15, pady=10)\n",
    "button_container.columnconfigure(0, weight=1)\n",
    "button_container.columnconfigure(1, weight=1)\n",
    "button_container.columnconfigure(2, weight=1)\n",
    "\n",
    "# Create buttons with consistent styling\n",
    "generate_button = ttk.Button(button_container, text=\"📷 Generate Dataset\", style=\"Accent.TButton\")\n",
    "generate_button.grid(row=0, column=0, padx=10, pady=5, sticky=\"ew\")\n",
    "\n",
    "train_button = ttk.Button(button_container, text=\"🧠 Train Model\", style=\"Accent.TButton\")\n",
    "train_button.grid(row=0, column=1, padx=10, pady=5, sticky=\"ew\")\n",
    "\n",
    "detect_button = ttk.Button(button_container, text=\"👁️ Detect Faces\", style=\"Accent.TButton\")\n",
    "detect_button.grid(row=0, column=2, padx=10, pady=5, sticky=\"ew\")\n",
    "\n",
    "# Log area with dark theme\n",
    "log_frame = ttk.Frame(main_frame, style=\"Card.TFrame\")\n",
    "log_frame.pack(fill=tk.BOTH, expand=True, pady=10, padx=5)\n",
    "\n",
    "log_header = ttk.Frame(log_frame, style=\"Header.TFrame\")\n",
    "log_header.pack(fill=tk.X)\n",
    "\n",
    "log_title = ttk.Label(log_header, text=\"System Log\", style=\"Header.TLabel\")\n",
    "log_title.pack(padx=10, pady=5, anchor=tk.W)\n",
    "\n",
    "# Dark styled log with good contrast\n",
    "log_area = scrolledtext.ScrolledText(log_frame, \n",
    "                                   font=(\"Consolas\", 10),\n",
    "                                   bg=\"#1A1A1A\", \n",
    "                                   fg=\"#E0E0E0\", \n",
    "                                   insertbackground=THEME[\"text\"],\n",
    "                                   relief=\"flat\",\n",
    "                                   height=10)\n",
    "log_area.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)\n",
    "log_area.config(state=tk.DISABLED)\n",
    "\n",
    "# Progress section\n",
    "progress_frame = ttk.Frame(main_frame, style=\"Card.TFrame\")\n",
    "progress_frame.pack(fill=tk.X, pady=10, padx=5)\n",
    "\n",
    "progress_var = tk.DoubleVar(value=0)\n",
    "progress_bar = ttk.Progressbar(progress_frame, \n",
    "                             orient=\"horizontal\", \n",
    "                             length=100, \n",
    "                             mode=\"determinate\",\n",
    "                             variable=progress_var)\n",
    "progress_bar.pack(fill=tk.X, padx=10, pady=10)\n",
    "\n",
    "# Status bar\n",
    "status_var = tk.StringVar(value=\"Ready\")\n",
    "status_bar = ttk.Label(window, textvariable=status_var, style=\"Status.TLabel\")\n",
    "status_bar.pack(side=tk.BOTTOM, fill=tk.X)\n",
    "\n",
    "# Store user names mapped to IDs\n",
    "user_names_file = \"user_names.json\"\n",
    "user_names = {}\n",
    "if os.path.exists(user_names_file):\n",
    "    try:\n",
    "        with open(user_names_file, 'r') as f:\n",
    "            user_names = json.load(f)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Function to update log with dark theme colors\n",
    "def update_log(message, message_type=\"INFO\"):\n",
    "    log_area.config(state=tk.NORMAL)\n",
    "    timestamp = time.strftime(\"%H:%M:%S\")\n",
    "    \n",
    "    # Color code messages by type\n",
    "    if message_type == \"ERROR\":\n",
    "        tag = \"error\"\n",
    "        log_area.tag_config(tag, foreground=THEME[\"error\"], font=(\"Consolas\", 10, \"bold\"))\n",
    "    elif message_type == \"SUCCESS\":\n",
    "        tag = \"success\"\n",
    "        log_area.tag_config(tag, foreground=THEME[\"success\"], font=(\"Consolas\", 10, \"bold\"))\n",
    "    elif message_type == \"WARNING\":\n",
    "        tag = \"warning\"\n",
    "        log_area.tag_config(tag, foreground=THEME[\"warning\"], font=(\"Consolas\", 10))\n",
    "    else:\n",
    "        tag = \"info\"\n",
    "        log_area.tag_config(tag, foreground=THEME[\"accent2\"], font=(\"Consolas\", 10))\n",
    "    \n",
    "    prefix = f\"[{message_type}]\" if message_type != \"INFO\" else \"\"\n",
    "    log_area.insert(tk.END, f\"{timestamp} {prefix} {message}\\n\", tag)\n",
    "    log_area.see(tk.END)\n",
    "    log_area.config(state=tk.DISABLED)\n",
    "    status_var.set(message)\n",
    "\n",
    "def update_button_states():\n",
    "    # Count dataset files\n",
    "    data_count = 0\n",
    "    if os.path.exists(\"data\"):\n",
    "        data_count = len([f for f in os.listdir(\"data\") if f.endswith('.jpg')])\n",
    "    \n",
    "    # Check if classifier exists\n",
    "    classifier_exists = os.path.exists(\"classifier.xml\")\n",
    "    \n",
    "    # Update button states\n",
    "    if data_count == 0:\n",
    "        train_button.config(state=tk.DISABLED)\n",
    "    else:\n",
    "        train_button.config(state=tk.NORMAL)\n",
    "    \n",
    "    if not classifier_exists:\n",
    "        detect_button.config(state=tk.DISABLED)\n",
    "    else:\n",
    "        detect_button.config(state=tk.NORMAL)\n",
    "    \n",
    "    # Update status message\n",
    "    if data_count > 0:\n",
    "        update_log(f\"Dataset ready: {data_count} images.\", \"SUCCESS\")\n",
    "\n",
    "def train_classifier():\n",
    "    if name_entry.get().strip() == \"\":\n",
    "        messagebox.showwarning(\"Input Required\", \"Please enter a name for the user\")\n",
    "        return\n",
    "        \n",
    "    data_dir = \"data\"\n",
    "    if not os.path.exists(data_dir) or len(os.listdir(data_dir)) == 0:\n",
    "        update_log(\"No images found in data directory.\", \"ERROR\")\n",
    "        messagebox.showerror(\"Training Error\", \"No face images found. Generate dataset first.\")\n",
    "        return\n",
    "    \n",
    "    path = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.jpg')]\n",
    "    update_log(f\"Training with {len(path)} images...\")\n",
    "    \n",
    "    # Disable buttons during training\n",
    "    train_button.config(state=tk.DISABLED)\n",
    "    generate_button.config(state=tk.DISABLED)\n",
    "    detect_button.config(state=tk.DISABLED)\n",
    "    \n",
    "    def training_thread():\n",
    "        faces = []\n",
    "        ids = []\n",
    "        progress_var.set(0)\n",
    "        \n",
    "        for i, image_path in enumerate(path):\n",
    "            try:\n",
    "                img = Image.open(image_path).convert('L')\n",
    "                imageNp = np.array(img, 'uint8')\n",
    "                id = int(os.path.split(image_path)[1].split(\".\")[1])\n",
    "                \n",
    "                faces.append(imageNp)\n",
    "                ids.append(id)\n",
    "                \n",
    "                # Update progress\n",
    "                progress = (i + 1) / len(path) * 100\n",
    "                progress_var.set(progress)\n",
    "                \n",
    "                if i % 10 == 0:\n",
    "                    status_var.set(f\"Training progress: {progress:.1f}%\")\n",
    "                    window.update_idletasks()\n",
    "                \n",
    "            except Exception as e:\n",
    "                update_log(f\"Error processing {os.path.basename(image_path)}: {e}\", \"ERROR\")\n",
    "        \n",
    "        if not faces:\n",
    "            update_log(\"No valid face images found.\", \"ERROR\")\n",
    "            window.after(0, lambda: update_button_states())\n",
    "            return\n",
    "            \n",
    "        ids = np.array(ids)\n",
    "        \n",
    "        try:\n",
    "            clf = cv2.face.LBPHFaceRecognizer_create()\n",
    "            update_log(f\"Training model...\", \"INFO\")\n",
    "            clf.train(faces, ids)\n",
    "            clf.write(\"classifier.xml\")\n",
    "            update_log(\"Training completed successfully!\", \"SUCCESS\")\n",
    "            progress_var.set(100)\n",
    "            messagebox.showinfo(\"Success\", \"Training completed successfully!\")\n",
    "        except Exception as e:\n",
    "            update_log(f\"Training error: {e}\", \"ERROR\")\n",
    "        \n",
    "        window.after(0, lambda: update_button_states())\n",
    "    \n",
    "    threading.Thread(target=training_thread, daemon=True).start()\n",
    "\n",
    "def detect_faces():\n",
    "    if not os.path.exists(\"classifier.xml\"):\n",
    "        update_log(\"Classifier not found. Train the model first.\", \"ERROR\")\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists(\"haarcascade_frontalface_default.xml\"):\n",
    "        update_log(\"Missing face cascade file.\", \"ERROR\")\n",
    "        return\n",
    "    \n",
    "    update_log(\"Starting face detection...\", \"INFO\")\n",
    "    \n",
    "    def draw_boundary(img, classifier, scaleFactor, minNeighbors, color, text, clf):\n",
    "        if img is None:\n",
    "            return img\n",
    "            \n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        features = classifier.detectMultiScale(gray_img, scaleFactor, minNeighbors)\n",
    "        \n",
    "        for (x,y,w,h) in features:\n",
    "            cv2.rectangle(img, (x,y), (x+w,y+h), color, 2)\n",
    "            \n",
    "            id, pred = clf.predict(gray_img[y:y+h,x:x+w])\n",
    "            confidence = int(100*(1-pred/300))\n",
    "            \n",
    "            # Use the stored name from our user_names dictionary\n",
    "            id_str = str(id)\n",
    "            if confidence > 75:\n",
    "                if id_str in user_names:\n",
    "                    name = user_names[id_str]\n",
    "                    text_color = (0, 255, 0)  # Green for high confidence\n",
    "                else:\n",
    "                    name = f\"User {id}\"\n",
    "                    text_color = (255, 255, 0)  # Yellow for unknown user\n",
    "                \n",
    "                cv2.putText(img, f\"{name} ({confidence}%)\", (x,y-10), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.75, text_color, 2)\n",
    "            else:\n",
    "                cv2.putText(img, f\"UNKNOWN ({confidence}%)\", (x,y-10), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0,0,255), 2)\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    faceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "    clf = cv2.face.LBPHFaceRecognizer_create()\n",
    "    clf.read(\"classifier.xml\")\n",
    "    \n",
    "    video_capture = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "    if not video_capture.isOpened():\n",
    "        update_log(\"Could not open camera\", \"ERROR\")\n",
    "        return\n",
    "\n",
    "    window_name = \"Face Recognition\"\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "    \n",
    "    # Create stylish overlay text for instructions\n",
    "    def add_overlay_text(img, text):\n",
    "        h, w = img.shape[:2]\n",
    "        overlay = img.copy()\n",
    "        cv2.rectangle(overlay, (0, h-40), (w, h), (0, 0, 0), -1)\n",
    "        alpha = 0.7\n",
    "        img = cv2.addWeighted(overlay, alpha, img, 1-alpha, 0)\n",
    "        cv2.putText(img, text, (10, h-15), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "        return img\n",
    "    \n",
    "    while True:\n",
    "        if cv2.getWindowProperty(window_name, cv2.WND_PROP_VISIBLE) < 1:\n",
    "            break\n",
    "            \n",
    "        ret, img = video_capture.read()\n",
    "        if not ret or img is None:\n",
    "            break\n",
    "            \n",
    "        img = draw_boundary(img, faceCascade, 1.3, 5, (255, 255, 255), \"Face\", clf)\n",
    "        img = add_overlay_text(img, \"Press 'ESC' or 'q' to exit\")\n",
    "        \n",
    "        cv2.imshow(window_name, img)\n",
    "\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 27 or key == ord('q'):  # ESC or q\n",
    "            break\n",
    "\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    update_log(\"Face detection completed\", \"SUCCESS\")\n",
    "\n",
    "def generate_dataset():\n",
    "    user_name = name_entry.get().strip()\n",
    "    if user_name == \"\":\n",
    "        messagebox.showwarning(\"Input Required\", \"Please enter a name for the user\")\n",
    "        return\n",
    "\n",
    "    update_log(f\"Generating dataset for: {user_name}\")\n",
    "    \n",
    "    if not os.path.exists(\"haarcascade_frontalface_default.xml\"):\n",
    "        update_log(\"Missing cascade file\", \"ERROR\")\n",
    "        return\n",
    "    \n",
    "    face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "    \n",
    "    if not os.path.exists(\"data\"):\n",
    "        os.makedirs(\"data\")\n",
    "    \n",
    "    # Disable buttons during generation\n",
    "    generate_button.config(state=tk.DISABLED)\n",
    "    train_button.config(state=tk.DISABLED)\n",
    "    detect_button.config(state=tk.DISABLED)\n",
    "    \n",
    "    progress_var.set(0)\n",
    "    \n",
    "    def face_cropped(img):\n",
    "        if img is None:\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "            \n",
    "            if len(faces) == 0:\n",
    "                return None\n",
    "                \n",
    "            for (x, y, w, h) in faces:\n",
    "                return img[y:y+h, x:x+w]\n",
    "            \n",
    "            return None\n",
    "        except Exception as e:\n",
    "            update_log(f\"Face detection error: {e}\", \"ERROR\")\n",
    "            return None\n",
    "    \n",
    "    def dataset_thread():\n",
    "        camera_index = 0\n",
    "        cap = None\n",
    "        \n",
    "        # Try to open camera\n",
    "        for idx in [0, 1]:\n",
    "            try:\n",
    "                cap = cv2.VideoCapture(idx, cv2.CAP_DSHOW)\n",
    "                if cap.isOpened():\n",
    "                    camera_index = idx\n",
    "                    time.sleep(1)\n",
    "                    ret, test_frame = cap.read()\n",
    "                    if ret and test_frame is not None:\n",
    "                        break\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            if cap:\n",
    "                cap.release()\n",
    "                cap = None\n",
    "        \n",
    "        if not cap:\n",
    "            update_log(\"Could not initialize camera\", \"ERROR\")\n",
    "            window.after(0, lambda: update_button_states())\n",
    "            return\n",
    "        \n",
    "        # Get next user ID\n",
    "        existing_ids = []\n",
    "        if os.path.exists(\"data\"):\n",
    "            for f in os.listdir(\"data\"):\n",
    "                try:\n",
    "                    if f.startswith(\"user.\") and f.endswith(\".jpg\"):\n",
    "                        parts = f.split(\".\")\n",
    "                        if len(parts) >= 2:\n",
    "                            existing_ids.append(int(parts[1]))\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        id = 1\n",
    "        if existing_ids:\n",
    "            id = max(existing_ids) + 1\n",
    "        \n",
    "        # Store user name with ID - THIS IS THE KEY FIX\n",
    "        user_names[str(id)] = user_name\n",
    "        with open(user_names_file, 'w') as f:\n",
    "            json.dump(user_names, f)\n",
    "        \n",
    "        update_log(f\"Using ID {id} for user: {user_name}\", \"INFO\")\n",
    "        img_id = 0\n",
    "        target_samples = 80\n",
    "        \n",
    "        window_name = \"Dataset Collection\"\n",
    "        cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret or frame is None:\n",
    "                break\n",
    "            \n",
    "            display_frame = frame.copy()\n",
    "            face = face_cropped(frame)\n",
    "            face_found = face is not None\n",
    "            \n",
    "            # Create UI overlay\n",
    "            h, w = display_frame.shape[:2]\n",
    "            overlay = display_frame.copy()\n",
    "            cv2.rectangle(overlay, (0, 0), (w, 40), (0, 0, 0), -1)\n",
    "            cv2.rectangle(overlay, (0, h-60), (w, h), (0, 0, 0), -1)\n",
    "            alpha = 0.7\n",
    "            display_frame = cv2.addWeighted(overlay, alpha, display_frame, 1-alpha, 0)\n",
    "            \n",
    "            # Add info text\n",
    "            progress_pct = (img_id / target_samples) * 100 if target_samples > 0 else 0\n",
    "            cv2.putText(display_frame, f\"Progress: {img_id}/{target_samples} ({progress_pct:.1f}%)\", \n",
    "                      (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 1)\n",
    "            \n",
    "            # Face detection guide\n",
    "            cv2.putText(display_frame, \n",
    "                      \"Face Detected\" if face_found else \"No Face - Center your face\", \n",
    "                      (10, h-40), cv2.FONT_HERSHEY_SIMPLEX, 0.7, \n",
    "                      (0, 255, 0) if face_found else (0, 0, 255), 1)\n",
    "            \n",
    "            # Add guide rectangle\n",
    "            center_x, center_y = w // 2, h // 2\n",
    "            guide_size = min(w, h) // 4\n",
    "            cv2.rectangle(display_frame, \n",
    "                        (center_x - guide_size, center_y - guide_size),\n",
    "                        (center_x + guide_size, center_y + guide_size),\n",
    "                        (0, 255, 255), 2)\n",
    "            \n",
    "            if face_found:\n",
    "                img_id += 1\n",
    "                face = cv2.resize(face, (200, 200))\n",
    "                face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "                file_name_path = f\"data/{user_name}.{id}.{img_id}.jpg\"\n",
    "                cv2.imwrite(file_name_path, face)\n",
    "                \n",
    "                # Update progress\n",
    "                progress = (img_id / target_samples) * 100\n",
    "                progress_var.set(progress)\n",
    "                \n",
    "                if img_id % 10 == 0:\n",
    "                    update_log(f\"Collected {img_id}/{target_samples} samples\", \"INFO\")\n",
    "            \n",
    "            cv2.imshow(window_name, display_frame)\n",
    "            \n",
    "            key = cv2.waitKey(100)\n",
    "            if key == 27 or img_id >= target_samples:\n",
    "                break\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        update_log(f\"Dataset generation completed: {img_id} samples\", \"SUCCESS\")\n",
    "        messagebox.showinfo(\"Success\", f\"Generated {img_id} samples for {user_name}\")\n",
    "        \n",
    "        window.after(0, lambda: update_button_states())\n",
    "    \n",
    "    threading.Thread(target=dataset_thread, daemon=True).start()\n",
    "\n",
    "# Connect buttons to functions\n",
    "generate_button.config(command=generate_dataset)\n",
    "train_button.config(command=train_classifier)\n",
    "detect_button.config(command=detect_faces)\n",
    "\n",
    "# Initial setup\n",
    "def startup():\n",
    "    update_log(\"Welcome to Face Recognition System\")\n",
    "    if not os.path.exists(\"data\"):\n",
    "        os.makedirs(\"data\")\n",
    "    if not os.path.exists(\"haarcascade_frontalface_default.xml\"):\n",
    "        update_log(\"Missing cascade file - please download\", \"WARNING\")\n",
    "    update_button_states()\n",
    "\n",
    "window.after(100, startup)\n",
    "window.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
